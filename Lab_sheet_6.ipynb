{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **In this Lab, there is one exercise for evaluation at the end of this sheet. Do your submissions by 12 Nov, 11am. Submit a new colab file containing the code with supporting libraries and output required for your answer. Do not share the original labsheet code in your submission..**\n",
        "\n",
        "*Submission Link:*[Upload Here](https://forms.gle/XkzCMM3KCVyBympj9)"
      ],
      "metadata": {
        "id": "SWydy3a5OkcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "[https://karpathy.github.io/2015/05/21/rnn-effectiveness/](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
      ],
      "metadata": {
        "id": "Ujeku2MRN1H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook provides a comprehensive overview of building and training a basic RNN for a character-level language modeling task. It covers data preprocessing, model definition, training, and using the model for predictions."
      ],
      "metadata": {
        "id": "8yTN1IhqijWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['hey how are you', 'good i am fine', 'have a nice day']"
      ],
      "metadata": {
        "id": "ZKpbYpCR3Oae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = set(''.join(text))"
      ],
      "metadata": {
        "id": "eKOQk4sK3tp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agtU6Ckh4EMp",
        "outputId": "be990e71-5aee-48eb-98c7-c852eff80575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " 'a',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'r',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'y'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_map = dict(enumerate(chars))"
      ],
      "metadata": {
        "id": "GtF8RtIn4Kb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgq_nONZ4YC9",
        "outputId": "4c0df10d-b8ae-4adf-bc88-fa8d5b549657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'v',\n",
              " 1: 'y',\n",
              " 2: 'h',\n",
              " 3: ' ',\n",
              " 4: 'd',\n",
              " 5: 'f',\n",
              " 6: 'a',\n",
              " 7: 'n',\n",
              " 8: 'c',\n",
              " 9: 'r',\n",
              " 10: 'w',\n",
              " 11: 'g',\n",
              " 12: 'u',\n",
              " 13: 'm',\n",
              " 14: 'i',\n",
              " 15: 'o',\n",
              " 16: 'e'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_map = {char:ind for ind, char in int_map.items()}"
      ],
      "metadata": {
        "id": "eUbA3avr4YtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acnQJN-84hxM",
        "outputId": "d04466f5-48ef-4886-8ac3-a4a6caedfcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'v': 0,\n",
              " 'y': 1,\n",
              " 'h': 2,\n",
              " ' ': 3,\n",
              " 'd': 4,\n",
              " 'f': 5,\n",
              " 'a': 6,\n",
              " 'n': 7,\n",
              " 'c': 8,\n",
              " 'r': 9,\n",
              " 'w': 10,\n",
              " 'g': 11,\n",
              " 'u': 12,\n",
              " 'm': 13,\n",
              " 'i': 14,\n",
              " 'o': 15,\n",
              " 'e': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_unique_chars = len(char_map)"
      ],
      "metadata": {
        "id": "RG4Tq6Ur4jlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_unique_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tdT70Rt4syn",
        "outputId": "2914c2c1-59aa-4b8b-a765-1e8c4577ed6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = len(max(text, key=len))"
      ],
      "metadata": {
        "id": "QbI58BeH4uMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d95_oKtS8YU3",
        "outputId": "8634e65c-a166-4a55-f9f4-4292d2f59a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the items must be of the same dims if we want to stack them into a batch\n",
        "\n",
        "for example, say we have a dataset of images\n",
        "\n",
        "and say our batch size is 30\n",
        "\n",
        "256x256\n",
        "\n",
        "512x512\n",
        "\n",
        "(30, 3, 256, 256)"
      ],
      "metadata": {
        "id": "r2KB-qlN49Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterating over my sentences in the dataset\n",
        "for i in range(len(text)):\n",
        "  while(len(text[i]))<maxlen:\n",
        "    text[i] += ' '"
      ],
      "metadata": {
        "id": "smipJY5V42X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnNBjCjj5bqg",
        "outputId": "6099c597-a3f6-42c8-9a35-891265ec8415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey how are you', 'good i am fine ', 'have a nice day']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = list()\n",
        "target_seq = list()\n",
        "\n",
        "\n",
        "for i in range(len(text)):\n",
        "  input_seq.append(text[i][:-1])\n",
        "  target_seq.append(text[i][1:])\n"
      ],
      "metadata": {
        "id": "bCDZUPPW5d-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZpGA-lz57JU",
        "outputId": "2b6197f4-e340-4dc1-d717-f2f984ecf43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey how are yo', 'good i am fine', 'have a nice da']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXYfvZLV58P6",
        "outputId": "1c004fa4-7880-4fe6-c3e1-d249d475670a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ey how are you', 'ood i am fine ', 'ave a nice day']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "  input_seq[i] = [char_map[character] for character in input_seq[i]]\n",
        "  target_seq[i] = [char_map[character] for character in target_seq[i]]\n"
      ],
      "metadata": {
        "id": "VsDUYfm059Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LspEpriT6dKL",
        "outputId": "ea251df2-725c-451a-b397-3402b950867c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 16, 1, 3, 2, 15, 10, 3, 6, 9, 16, 3, 1, 15],\n",
              " [11, 15, 15, 4, 3, 14, 3, 6, 13, 3, 5, 14, 7, 16],\n",
              " [2, 6, 0, 16, 3, 6, 3, 7, 14, 8, 16, 3, 4, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQxQ-73N6eRD",
        "outputId": "53a5b8d2-fa2b-405e-f9b6-e64b47be81e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[16, 1, 3, 2, 15, 10, 3, 6, 9, 16, 3, 1, 15, 12],\n",
              " [15, 15, 4, 3, 14, 3, 6, 13, 3, 5, 14, 7, 16, 3],\n",
              " [6, 0, 16, 3, 6, 3, 7, 14, 8, 16, 3, 4, 6, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you want to get the one-hot embedding/vector corresponding to 4\n",
        "\n",
        "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "GqwBfwUu6e8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c321b7-ed3d-42da-8358-80af690fe8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "4LF7FceQ8N3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "num_of_sentences x num_characters_in_sentence x length_of_one_hot_vector"
      ],
      "metadata": {
        "id": "vJZf4nZk8lHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(sequence, num_unique_chars, seq_len, batch_size):\n",
        "\n",
        "  features = np.zeros((batch_size, seq_len, num_unique_chars), dtype=np.float32)\n",
        "  # for each sentence\n",
        "  for i in range(batch_size):\n",
        "    # for each character in a sentence\n",
        "    for u in range(seq_len):\n",
        "      features[i, u, sequence[i][u]] = 1\n",
        "\n",
        "  return features\n"
      ],
      "metadata": {
        "id": "TaVZppoQ737_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = len(text)\n",
        "seq_len = maxlen - 1"
      ],
      "metadata": {
        "id": "yx9dcel19ryR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = one_hot_encode(input_seq, num_unique_chars, seq_len, batch_size)"
      ],
      "metadata": {
        "id": "-Rr4Ml-s9i7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(input_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3EXeHBp95V7",
        "outputId": "c4cdb40f-d238-4396-dc59-b4e28a3eb022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.from_numpy(input_seq)\n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "metadata": {
        "id": "x-HhSPkG97Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "9QDtJ81X-XaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the model"
      ],
      "metadata": {
        "id": "4C5U-Enu-qIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "    super().__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "    return hidden\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "\n",
        "    out, hidden  = self.rnn(x, hidden)\n",
        "\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, hidden\n"
      ],
      "metadata": {
        "id": "9SreUrzE-ZJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size = num_unique_chars, output_size = num_unique_chars, hidden_dim = 12, n_layers = 1)"
      ],
      "metadata": {
        "id": "P_RvFow4ANt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "0wAfLH_vB09g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "L75EoHaDB2Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "W8M4P8osB8mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = input_seq.to(device)"
      ],
      "metadata": {
        "id": "vR6rFj9DCB4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "-E33-ZAkNq82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  output, hidden = model(input_seq)\n",
        "\n",
        "  output = output.to(device)\n",
        "  target_seq = target_seq.to(device)\n",
        "\n",
        "  epoch_loss = loss(output.view(-1, output.shape[-1]), target_seq.view(-1).long())\n",
        "\n",
        "  epoch_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"Epoch: {}/{}............\".format(epoch, n_epochs), end = ' ')\n",
        "    print(\"Loss: {:.4f}\".format(epoch_loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWV_Nwf7C1ld",
        "outputId": "fd2e499a-d7df-4ce7-d981-df916a77c8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/100............ Loss: 2.4118\n",
            "Epoch: 20/100............ Loss: 2.1012\n",
            "Epoch: 30/100............ Loss: 1.6987\n",
            "Epoch: 40/100............ Loss: 1.2996\n",
            "Epoch: 50/100............ Loss: 0.9236\n",
            "Epoch: 60/100............ Loss: 0.6218\n",
            "Epoch: 70/100............ Loss: 0.4170\n",
            "Epoch: 80/100............ Loss: 0.2842\n",
            "Epoch: 90/100............ Loss: 0.2036\n",
            "Epoch: 100/100............ Loss: 0.1550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, hidden = model(input_seq)"
      ],
      "metadata": {
        "id": "g-heVlUCDV7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJKVUmxWDuSZ",
        "outputId": "308f61ac-5c86-41e6-ce19-cd7a3cb848d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 14, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKeIKd6XD2cT",
        "outputId": "54fe8ea9-629f-4202-e48c-5e2a402e5628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq.view(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Nf3RGfEPET",
        "outputId": "3546eed1-a861-4bf2-de14-8836515c04fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16.,  1.,  3.,  2., 15., 10.,  3.,  6.,  9., 16.,  3.,  1., 15., 12.,\n",
              "        15., 15.,  4.,  3., 14.,  3.,  6., 13.,  3.,  5., 14.,  7., 16.,  3.,\n",
              "         6.,  0., 16.,  3.,  6.,  3.,  7., 14.,  8., 16.,  3.,  4.,  6.,  1.],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get predictions from our trained model"
      ],
      "metadata": {
        "id": "IAhGrXlzE3cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# characters = ['h', 'e', 'y']\n",
        "def predict(model, characters):\n",
        "  characters = np.array([[char_map[c] for c in characters]])\n",
        "  characters = one_hot_encode(characters, num_unique_chars, characters.shape[1], 1)\n",
        "  characters = torch.from_numpy(characters)\n",
        "  characters = characters.to(device)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  out, hidden = model(characters)\n",
        "\n",
        "  prob = nn.functional.softmax(torch.squeeze(out, dim=0)[-1], dim=0)\n",
        "\n",
        "  char_ind = torch.argmax(prob, dim=0)\n",
        "\n",
        "  return int_map[char_ind.item()], hidden"
      ],
      "metadata": {
        "id": "IK6HeVhmEdN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, out_len, start):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  start = start.lower()\n",
        "\n",
        "  chars = [ch for ch in start]\n",
        "\n",
        "  size = out_len - len(chars)\n",
        "\n",
        "  for _ in range(size):\n",
        "    char, h = predict(model, chars)\n",
        "    chars.append(char)\n",
        "\n",
        "  return ''.join(chars)"
      ],
      "metadata": {
        "id": "PAo9IImQHD16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample(model, 15, 'have')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JJkesX9XHRyk",
        "outputId": "848019da-681d-409a-92c4-174d5cb9321e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have a nice day'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.01, 0.02, 0.3, 0.04, .....]\n",
        "# you apply softmax to this -> you get a list of probabilites\n",
        "# you use torch.argmax to get the index corresponding to the max value\n",
        "# say our max value -> 3\n",
        "# we use the int_map to convert 3 to 'i'\n"
      ],
      "metadata": {
        "id": "vbqaF3DaFzOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:**\n",
        "Your task is to modify the existing character-level RNN model to create a word-level language model. Instead of predicting the next character, your model should predict the next word in a sequence of words.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "\n",
        "1.   **Data Preprocessing:** Use a larger text dataset (you can choose a dataset or use any text corpus available in the lab). Tokenize the text data into words instead of characters. Create a mapping of each unique word to an integer (word to index) and the reverse mapping (index to word).\n",
        "Prepare your input and target sequences based on words.\n",
        "2.   **Model Modifications:** Adjust the input and output dimensions of your RNN model to accommodate the size of the word vocabulary (number of unique words). Consider experimenting with the size of the hidden layer or adding more layers to the RNN.\n",
        "3. **Training:** Train your model with the word-level sequences. Pay attention to how the choice of sequence length impacts the training and results.\n",
        "4. **Evaluation and Generation:** Evaluate your model's performance. How well does it predict the next word? Implement a function to generate a sequence of words given a starting word or phrase.\n"
      ],
      "metadata": {
        "id": "qpSdf7c6f5xI"
      }
    }
  ]
}